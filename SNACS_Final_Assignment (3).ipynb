{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import needed libaries"
      ],
      "metadata": {
        "id": "CnWdkGWgZrXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install infomap\n",
        "!pip install python-louvain\n",
        "!pip install cdlib"
      ],
      "metadata": {
        "id": "BORCPj8IYn8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from infomap import Infomap\n",
        "from math import sqrt\n",
        "import networkx as nx\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import community.community_louvain as community_louvain\n",
        "from sklearn.metrics import f1_score\n",
        "from cdlib import algorithms"
      ],
      "metadata": {
        "id": "oFx9KP1xV123"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cada implementation from GitHub"
      ],
      "metadata": {
        "id": "b9gFClaIyf3I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a8bdVe_OvYE"
      },
      "outputs": [],
      "source": [
        "class cada():\n",
        "    def __init__(self, graph, algorithm='louvain', resolution=0.1):\n",
        "        if algorithm == 'louvain':\n",
        "            partition = community_louvain.best_partition(graph, resolution=resolution)\n",
        "        elif algorithm == 'infomap':\n",
        "            partition = self.run_infomap(graph)\n",
        "        elif algorithm == 'label_propagation':\n",
        "            partition = self.run_label_propagation(graph)\n",
        "        elif algorithm == 'walktrap':\n",
        "            partition = self.run_walktrap(graph)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown algorithm: {algorithm}\")\n",
        "\n",
        "        communities = set()\n",
        "        for node in graph.nodes():\n",
        "            if node in partition:\n",
        "                communities.add(partition[node])\n",
        "\n",
        "        anom_score = {}\n",
        "\n",
        "        # Compute anomaly score for each node\n",
        "        for node in graph.nodes():\n",
        "            comms = {}\n",
        "            for neighbor in graph.neighbors(node):\n",
        "                if neighbor != node:\n",
        "                    if partition[neighbor] not in comms:\n",
        "                        comms[partition[neighbor]] = 0\n",
        "\n",
        "                    comms[partition[neighbor]] += 1\n",
        "\n",
        "            if len(comms) > 0:\n",
        "                # The number of communities it is connected to.\n",
        "                comms = np.array(list(comms.values()))\n",
        "                # print('nr communities connected', comms)\n",
        "                max_com = np.max(comms)\n",
        "                # print('Maxcommunity', max_com)\n",
        "                comms = comms / max_com\n",
        "                # print('Communities normalized', comms)\n",
        "                anom_score[node] = np.sum(comms)\n",
        "                # print('Anomaly score., ', anom_score[node])\n",
        "\n",
        "        self.anomaly_scores = sorted(anom_score.items(), key=lambda x: x[1])[::-1]\n",
        "\n",
        "    def run_infomap(self, graph):\n",
        "        \"\"\"\n",
        "        Runs Infomap with infomap package\n",
        "        \"\"\"\n",
        "        infomapSimple = Infomap(\"--two-level --silent\")\n",
        "\n",
        "        # Add edges to the Infomap object directly\n",
        "        for e in graph.edges():\n",
        "            infomapSimple.addLink(e[0], e[1])\n",
        "\n",
        "        # Run Infomap\n",
        "        infomapSimple.run()\n",
        "\n",
        "        # Get the resulting partition\n",
        "        partition = {}\n",
        "        for node in infomapSimple.iterTree():\n",
        "            if node.isLeaf():\n",
        "                partition[node.physicalId] = node.moduleIndex()\n",
        "\n",
        "        return partition\n",
        "\n",
        "    def run_label_propagation(self, graph):\n",
        "        \"\"\"\n",
        "        Runs Label Propagation using NetworkX\n",
        "        \"\"\"\n",
        "        communities = nx.algorithms.community.label_propagation.asyn_lpa_communities(graph)\n",
        "        partition = {}\n",
        "        for i, community in enumerate(communities):\n",
        "            for node in community:\n",
        "                partition[node] = i\n",
        "        return partition\n",
        "\n",
        "    def run_walktrap(self, graph):\n",
        "        \"\"\"\n",
        "        Runs Walktrap using the cdlib library.\n",
        "        \"\"\"\n",
        "        walktrap_communities = algorithms.walktrap(graph)\n",
        "        partition = {}\n",
        "        for i, community in enumerate(walktrap_communities.communities):\n",
        "            for node in community:\n",
        "                partition[node] = i\n",
        "        return partition\n",
        "\n",
        "    # For calculating anomaly score\n",
        "    def get_anomaly_scores(self, nr_anomalies=None):\n",
        "        \"\"\"\n",
        "        Returns tuple (node, anomaly_score) for either nr_anomalies or all\n",
        "        \"\"\"\n",
        "        if nr_anomalies:\n",
        "            return self.anomaly_scores[:nr_anomalies]\n",
        "        else:\n",
        "            return self.anomaly_scores\n",
        "\n",
        "    # Get the top anomalies (so with the highest anomaly scores)\n",
        "    def get_top_anomalies(self, nr_anomalies=100):\n",
        "        \"\"\"\n",
        "        Returns highest scoring anomalies\n",
        "        \"\"\"\n",
        "        anomalies = []\n",
        "        for anomaly in self.anomaly_scores[:nr_anomalies]:\n",
        "            anomalies.append(anomaly[0])\n",
        "\n",
        "        return anomalies\n",
        "\n",
        "    # Get all anomalies with an anomaly score above a certain threshold\n",
        "    def get_anomalies_threshold(self, threshold):\n",
        "        \"\"\"\n",
        "        Returns anomalies that are above a certain threshold.\n",
        "        \"\"\"\n",
        "        anomalies = []\n",
        "\n",
        "        for anomaly in self.anomaly_scores:\n",
        "            if anomaly[1] > threshold:\n",
        "                anomalies.append(anomaly[0])\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate a synthetic network dataset"
      ],
      "metadata": {
        "id": "f6Y8W44RyzC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_lfr_benchmark(n, tau1, tau2, mu, k, k_max, seed):\n",
        "    k = int(round(k))\n",
        "    k_max = int(round(k_max))\n",
        "    G = nx.LFR_benchmark_graph(n, tau1, tau2, mu, average_degree=k, max_degree=k_max,seed=seed)\n",
        "    return G"
      ],
      "metadata": {
        "id": "ww92vuJpcZb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding random anomalies to the graph"
      ],
      "metadata": {
        "id": "cDYMIu8havOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inject_random_anomalies(G, k, k_max, tau1):\n",
        "    num_anomalies = G.number_of_nodes() // 100\n",
        "    new_nodes = []\n",
        "    index = G.number_of_nodes()\n",
        "    # Add num_anomalies new nodes\n",
        "    for i in range(num_anomalies):\n",
        "        new_node = index + i\n",
        "        # Set the number of edges using a power-law distribution\n",
        "        num_edges = np.clip(int(np.random.pareto(tau1 - 1) + k), int(k), int(k_max))\n",
        "        # Randomly select neighbors from existing nodes\n",
        "        neighbors = np.random.choice(list(G.nodes), num_edges, replace=False)\n",
        "        # Add the new node to the graph\n",
        "        G.add_node(new_node)\n",
        "        # Connect the new node to the chosen neighbors\n",
        "        for neighbor in neighbors:\n",
        "            G.add_edge(new_node, neighbor)\n",
        "        # Add the new node to the list of anomalies for reference\n",
        "        new_nodes.append(new_node)\n",
        "    return G, new_nodes\n"
      ],
      "metadata": {
        "id": "gqLMqKNUzDPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the mean f1 score from a graph"
      ],
      "metadata": {
        "id": "A7ORatyH2yWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_f1(graphs, anomalies, algorithm='louvain'):\n",
        "    f1_list = []\n",
        "    for index, graph in enumerate(graphs):\n",
        "        # Initialize anomaly detector with specified algorithm\n",
        "        anomaly_detector = cada(graph, algorithm=algorithm)\n",
        "        predicted_anomalies = anomaly_detector.get_top_anomalies(100)\n",
        "        # Create a list of all node IDs\n",
        "        all_nodes = set(range(graph.number_of_nodes()))\n",
        "\n",
        "        # Create true labels (1 for true anomalies, 0 for all other nodes)\n",
        "        true_labels = []\n",
        "        for node in all_nodes:\n",
        "            # Use anomalies from inject_random_anomalies, not get_top_anomalies\n",
        "            if node in anomalies[index]:\n",
        "                true_labels.append(1)\n",
        "            else:\n",
        "                true_labels.append(0)\n",
        "\n",
        "        # Create predicted labels (1 for predicted anomalies, 0 for all other nodes)\n",
        "        predicted_labels = []\n",
        "        for node in all_nodes:\n",
        "            if node in predicted_anomalies:  # Use predicted_anomalies here\n",
        "                predicted_labels.append(1)\n",
        "            else:\n",
        "                predicted_labels.append(0)\n",
        "\n",
        "        # Calculate the F1 score\n",
        "        f1 = f1_score(true_labels, predicted_labels)\n",
        "        f1_list.append(f1)\n",
        "    return np.mean(f1_list)"
      ],
      "metadata": {
        "id": "x-97VEZ9SMmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with different node sizes"
      ],
      "metadata": {
        "id": "PQoT997-UY9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the non-changing parameters"
      ],
      "metadata": {
        "id": "X3DhqsWxUeTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 0.2\n",
        "tau1 = 3\n",
        "tau2 = 2\n",
        "t1 = 4"
      ],
      "metadata": {
        "id": "DkegFv-CUc8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate f1 score with a given node size"
      ],
      "metadata": {
        "id": "avRA36JAVIWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_node_size(n, algorithm='louvain'):\n",
        "    graphs = []\n",
        "    all_anomalies = []\n",
        "    # Create 5 different graphs with the same parameter but different seed\n",
        "    k = (2*n**1.15) / n\n",
        "    k_max = n**(1/(t1-1))\n",
        "    for i in range(5):\n",
        "        G = generate_lfr_benchmark(n, tau1, tau2, mu, k, k_max, i)\n",
        "        G, anomalies = inject_random_anomalies(G, k, k_max, tau1)\n",
        "        graphs.append(G)\n",
        "        all_anomalies.append(anomalies)\n",
        "    f1 = mean_f1(graphs, all_anomalies, algorithm=algorithm)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "Kxo6UIazVGLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_sizes = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000,12000,13000,14000,15000]\n",
        "\n",
        "# Generate scores for Louvain\n",
        "scores_louvain = [f1_score_node_size(n, algorithm='louvain') for n in node_sizes]\n",
        "# Save in numpy in case your pc can't handle all algorithms at once\n",
        "np.save('/home/scores_louvain_n.npy', scores_louvain)"
      ],
      "metadata": {
        "id": "8Cpq44QHVVhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate scores for Infomap\n",
        "scores_infomap = [f1_score_node_size(n, algorithm='infomap') for n in node_sizes]\n",
        "# Save in numpy in case your pc can't handle all algorithms at once\n",
        "np.save('/home/scores_infomap_n.npy', scores_infomap)"
      ],
      "metadata": {
        "id": "1UVe8-jhWZKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate scores for Label Propagation\n",
        "scores_label_propagation = [f1_score_node_size(n, algorithm='label_propagation') for n in node_sizes]\n",
        "# Save in numpy in case your pc can't handle all algorithms at once\n",
        "np.save('/home/scores_label_n.npy', scores_label_propagation)"
      ],
      "metadata": {
        "id": "xEJ5Q9RZWZwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate scores for Walktrap\n",
        "scores_walktrap = [f1_score_node_size(n, algorithm='walktrap') for n in node_sizes]\n",
        "# Save in numpy in case your pc can't handle all algorithms at once\n",
        "np.save('/home/scores_walktrap_n.npy', scores_walktrap)"
      ],
      "metadata": {
        "id": "s_XPUFCJWcgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data and plot the f1 scores for the different node sizes"
      ],
      "metadata": {
        "id": "E6EIZqhqW0FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores_louvain = np.load('/home/scores_louvain.npy').tolist()\n",
        "scores_label_propagation = np.load('/home/scores_label.npy').tolist()\n",
        "scores_infomap = np.load('/home/scores_infomap.npy').tolist()\n",
        "scores_walktrap = np.load('/home/scores_walktrap.npy').tolist()\n",
        "\n",
        "# Create tick labels by dividing node_sizes by 1000\n",
        "tick_labels = [size // 1000 for size in node_sizes]\n",
        "\n",
        "# Plot the results\n",
        "plt.plot(node_sizes, scores_louvain, '-o', label='Louvain')\n",
        "plt.plot(node_sizes, scores_infomap, '-o', label='Infomap')\n",
        "plt.plot(node_sizes, scores_label_propagation, '-o', label='Label Propagation')\n",
        "plt.plot(node_sizes, scores_walktrap, '-o', label='Walktrap')\n",
        "\n",
        "# Set ticks and labels\n",
        "plt.xticks(node_sizes, tick_labels)\n",
        "plt.xlabel('Node Size (X 1000)')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yRTo6058opKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with different mu"
      ],
      "metadata": {
        "id": "mhDUD57V3F2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the non-changing parameters"
      ],
      "metadata": {
        "id": "3XS3DD5eT-n4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10000\n",
        "tau1 = 3\n",
        "tau2 = 2\n",
        "k = (2*n**1.15) / n\n",
        "t1 = 4\n",
        "k_max = n**(1/(t1-1))"
      ],
      "metadata": {
        "id": "FdnBlkrf3CwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate f1 score with a given mu"
      ],
      "metadata": {
        "id": "-3xLTZOE416I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_mu(mu, algorithm='louvain'):\n",
        "    graphs = []\n",
        "    all_anomalies = []\n",
        "    # Create 5 different graphs with the same parameter but different seed\n",
        "    for i in range(5):\n",
        "        G = generate_lfr_benchmark(n, tau1, tau2, mu, k, k_max, i)\n",
        "        G, anomalies = inject_random_anomalies(G, k, k_max, tau1)\n",
        "        graphs.append(G)\n",
        "        all_anomalies.append(anomalies)\n",
        "    f1 = mean_f1(graphs, all_anomalies, algorithm=algorithm)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "iwVIK48940uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mus = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "# Generate scores for Louvain\n",
        "scores_louvain = [f1_score_mu(mu, algorithm='louvain') for mu in mus]\n",
        "np.save('/home/scores_louvain_mus.npy', scores_louvain)\n",
        "\n",
        "# Generate scores for Infomap\n",
        "scores_infomap = [f1_score_mu(mu, algorithm='infomap') for mu in mus]\n",
        "np.save('/home/scores_infomap_mus.npy', scores_infomap)\n",
        "\n",
        "# Generate scores for Label Propagation\n",
        "scores_label_propagation = [f1_score_mu(mu, algorithm='label_propagation') for mu in mus]\n",
        "np.save('/home/scores_labelpropagation_mus.npy', scores_label_propagation)\n",
        "\n",
        "# Generate scores for Walktrap\n",
        "scores_walktrap = [f1_score_mu(mu, algorithm='walktrap') for mu in mus]\n",
        "np.save('/home/scores_walktrap_mus.npy', scores_walktrap)"
      ],
      "metadata": {
        "id": "ORV7tojfUOM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(mus, scores_louvain, '-o', label='Louvain')\n",
        "plt.plot(mus, scores_infomap, '-o', label='Infomap')\n",
        "plt.plot(mus, scores_label_propagation, '-o', label='Label Propagation')\n",
        "plt.plot(mus, scores_walktrap, '-o', label='Walktrap')\n",
        "plt.xticks(mus)\n",
        "plt.xlabel('mu')\n",
        "plt.ylabel('f1 score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K3Crt-P26cyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the f1 scores for different mu"
      ],
      "metadata": {
        "id": "BbgcM8sgASRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results\n",
        "plt.plot(mus, scores_louvain, '-o', label='Louvain')\n",
        "plt.plot(mus, scores_infomap, '-o', label='Infomap')\n",
        "plt.plot(mus, scores_label_propagation, '-o', label='Label Propagation')\n",
        "plt.plot(mus, scores_walktrap, '-o', label='Walktrap')\n",
        "plt.xticks(mus)\n",
        "plt.xlabel('mu')\n",
        "plt.ylabel('f1 score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gtp8WBRaBezJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with different t1"
      ],
      "metadata": {
        "id": "bob2raHPtkhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the non-changing parameters"
      ],
      "metadata": {
        "id": "mSEdWjCXZF9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10000\n",
        "tau1 = 3\n",
        "tau2 = 2\n",
        "k = (2*n**1.15) / n\n",
        "mu = 0.2"
      ],
      "metadata": {
        "id": "hAa7qfmHB5YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate f1 score with a given t1"
      ],
      "metadata": {
        "id": "VQ_Cam8oZKhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_t1(t1, algorithm='louvain'):\n",
        "    graphs = []\n",
        "    all_anomalies = []\n",
        "    k_max = n**(1/(t1-1))\n",
        "    # Create 5 different graphs with the same parameter but different seed\n",
        "    for i in range(5):\n",
        "        G = generate_lfr_benchmark(n, tau1, tau2, mu, k, k_max, i)\n",
        "        G, anomalies = inject_random_anomalies(G, k, k_max, tau1)\n",
        "        graphs.append(G)\n",
        "        all_anomalies.append(anomalies)\n",
        "    f1 = mean_f1(graphs, all_anomalies, algorithm=algorithm)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "oxRpN5OMZJy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1s = [2, 3, 4, 5, 6]\n",
        "\n",
        "# Generate scores for Louvain\n",
        "scores_louvain = [f1_score_t1(t1, algorithm='louvain') for t1 in t1s]\n",
        "\n",
        "# Generate scores for Infomap\n",
        "scores_infomap = [f1_score_t1(t1, algorithm='infomap') for t1 in t1s]\n",
        "\n",
        "# Generate scores for Label Propagation\n",
        "scores_label_propagation = [f1_score_t1(t1, algorithm='label_propagation') for t1 in t1s]\n",
        "\n",
        "# Generate scores for Walktrap\n",
        "scores_walktrap = [f1_score_t1(t1, algorithm='walktrap') for t1 in t1s]"
      ],
      "metadata": {
        "id": "pRfC7G31ZdSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the f1 scores for different t1\n"
      ],
      "metadata": {
        "id": "wrMG26dJZlrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results\n",
        "plt.plot(t1s, scores_louvain, '-o', label='Louvain')\n",
        "plt.plot(t1s, scores_infomap, '-o', label='Infomap')\n",
        "plt.plot(t1s, scores_label_propagation, '-o', label='Label Propagation')\n",
        "plt.plot(t1s, scores_walktrap, '-o', label='Walktrap')\n",
        "plt.xlabel('t1')\n",
        "plt.ylabel('f1 score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vKqjXj9ZZ1Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with different tau1"
      ],
      "metadata": {
        "id": "EjHHvB98fX5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the non-changing parameters"
      ],
      "metadata": {
        "id": "c8FgxCTIg8xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10000\n",
        "tau2 = 2\n",
        "k = (2*n**1.15) / n\n",
        "mu = 0.2\n",
        "t1 = 4\n",
        "k_max = n**(1/(t1-1))"
      ],
      "metadata": {
        "id": "B0BEKocBfk8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate f1 score with a given tau1"
      ],
      "metadata": {
        "id": "eC0vL8iWhDqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_tau1(tau1, algorithm='louvain'):\n",
        "    graphs = []\n",
        "    all_anomalies = []\n",
        "    # Create 5 different graphs with the same parameter but different seed\n",
        "    for i in range(5):\n",
        "        G = generate_lfr_benchmark(n, tau1, tau2, mu, k, k_max, i)\n",
        "        G, anomalies = inject_random_anomalies(G, k, k_max, tau1)\n",
        "        graphs.append(G)\n",
        "        all_anomalies.append(anomalies)\n",
        "    f1 = mean_f1(graphs, all_anomalies, algorithm=algorithm)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "2LSn8NCtgTJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau1s = [2.0, 2.5, 3, 3.5, 4.0]\n",
        "\n",
        "scores_louvain = [f1_score_tau1(tau1, algorithm='louvain') for tau1 in tau1s]\n",
        "scores_infomap = [f1_score_tau1(tau1, algorithm='infomap') for tau1 in tau1s]\n",
        "scores_label_propagation = [f1_score_tau1(tau1, algorithm='label_propagation') for tau1 in tau1s]\n",
        "scores_walktrap = [f1_score_tau1(tau1, algorithm='walktrap') for tau1 in tau1s]"
      ],
      "metadata": {
        "id": "QGHxy40_gfZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/home/scores_louvain_tau1.npy', scores_louvain)\n",
        "np.save('/home/scores_infomap_tau1.npy', scores_infomap)\n",
        "np.save('/home/scores_labelpropagation_tau1.npy', scores_label_propagation)\n",
        "np.save('/home/scores_walktrap_tau1.npy', scores_walktrap)"
      ],
      "metadata": {
        "id": "0uI8j_hXh_WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the f1 scores for different tau1"
      ],
      "metadata": {
        "id": "onBxlMWLhH9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results\n",
        "plt.plot(tau1s, scores_louvain, '-o', label='Louvain')\n",
        "plt.plot(tau1s, scores_infomap, '-o', label='Infomap')\n",
        "plt.plot(tau1s, scores_label_propagation, '-o', label='Label Propagation')\n",
        "plt.plot(tau1s, scores_walktrap, '-o', label='Walktrap')\n",
        "plt.xlabel('tau1')\n",
        "plt.xticks(tau1s)\n",
        "plt.ylabel('f1 score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jmFA-8GhgtzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with different tau2"
      ],
      "metadata": {
        "id": "R04xc9KMjBaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the non-changing parameters"
      ],
      "metadata": {
        "id": "qRFgo8-gjdrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 10000\n",
        "tau1 = 3\n",
        "k = (2*n**1.15) / n\n",
        "mu = 0.2\n",
        "t1 = 4\n",
        "k_max = n**(1/(t1-1))"
      ],
      "metadata": {
        "id": "lG7THqn3jAo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate f1 score with a given tau2"
      ],
      "metadata": {
        "id": "hbdrHdOzinXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score_tau2(tau2, algorithm='louvain'):\n",
        "    graphs = []\n",
        "    all_anomalies = []\n",
        "    # Create 5 different graphs with the same parameter but different seed\n",
        "    for i in range(5):\n",
        "        G = generate_lfr_benchmark(n, tau1, tau2, mu, k, k_max, i)\n",
        "        G, anomalies = inject_random_anomalies(G, k, k_max, tau1)\n",
        "        graphs.append(G)\n",
        "        all_anomalies.append(anomalies)\n",
        "    f1 = mean_f1(graphs, all_anomalies, algorithm=algorithm)\n",
        "    return f1"
      ],
      "metadata": {
        "id": "w2tLCZWZilsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau2s = [1.5, 2, 2.5, 3]\n",
        "\n",
        "scores_louvain = [f1_score_tau2(tau2, algorithm='louvain') for tau2 in tau2s]\n",
        "scores_infomap = [f1_score_tau2(tau2, algorithm='infomap') for tau2 in tau2s]\n",
        "scores_label_propagation = [f1_score_tau2(tau2, algorithm='label_propagation') for tau2 in tau2s]\n",
        "scores_walktrap = [f1_score_tau2(tau2, algorithm='walktrap') for tau2 in tau2s]"
      ],
      "metadata": {
        "id": "kEqBqa7kjxYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/home/scores_louvain_tau2.npy', scores_louvain)\n",
        "np.save('/home/scores_infomap_tau2.npy', scores_infomap)\n",
        "np.save('/home/scores_labelpropagation_tau2.npy', scores_label_propagation)\n",
        "np.save('/home/scores_walktrap_tau2.npy', scores_walktrap)"
      ],
      "metadata": {
        "id": "_ndko5Z6kTkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the f1 scores for different tau2"
      ],
      "metadata": {
        "id": "G0YunaC_kQFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results\n",
        "plt.plot(tau2s, scores_louvain, '-o', label='Louvain')\n",
        "plt.plot(tau2s, scores_infomap, '-o', label='Infomap')\n",
        "plt.plot(tau2s, scores_label_propagation, '-o', label='Label Propagation')\n",
        "plt.plot(tau2s, scores_walktrap, '-o', label='Walktrap')\n",
        "plt.xlabel('tau2')\n",
        "plt.xticks(tau2s)\n",
        "plt.ylabel('f1 score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ufhFd6Y0kLY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}